{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "369192d7",
   "metadata": {},
   "source": [
    "## Neural Style Transfer\n",
    "\n",
    "Neural Style Transfer's first method is centred on directly optimising the pixel values of the image. Instead of training a network, we use one that has already been pretrained, and the loss is determined by using the features that have been extracted from it.\n",
    "\n",
    "But because we have to perform optimisation for each new style-content image pair, this approach is incredibly inefficient. Johnson et al. suggested utilising a feed-forward network to carry out Style Transfer. Therefore, we run the image through an Image Transformation Network and learn the weights of this network instead of optimising the image pixels. This is the strategy I used to complete this assignment. The sole disadvantage of this approach is that we would have to train a new network in order to adapt to a new art style because the network is limited to a single style.\n",
    "\n",
    "Additional research expands this to a greater number of styles per network, but due to time and resource limitations, I chose the less complicated method.\n",
    "\n",
    "We use one style image and a dataset of content images for training. Three different kinds of losses exist in our goal.\n",
    "\n",
    "1- Content Loss\n",
    "2- Style Loss\n",
    "3- Total Variation Loss\n",
    "\n",
    "A pre-trained VGG network's features are the basis for these losses. The majority of its foundation is empirical data. A well-trained CNN's earlier layers perform well at identifying minute details or, in a sense, the image's content. We use the Image Transformation Network to transform the input image, the style image, and the content image in each training example. The best results are obtained when the input image is taken empirically as the content image. The content loss is just the MSE between the feature responses of specific layers (for VGG16, _relu_1_2_ and _relu_2_2_ seem to work well and are the most used in literature). We feed the transformed image and the content image into the pretrained VGG.\n",
    "\n",
    "The correlation matrices of the feature responses are made similar in order to capture the style. More precisely, we calculate the correlation matrix of $C$ features of shape $HW$ if we have activations of some layer in the shape $C \\times H \\times W$. We carry out this action for activations from layers _relu_3_3_ and _relu_4_3_ in the instance of VGG16.\n",
    "\n",
    "All that the TV Loss does is encourage spatial smoothness in the final image by acting as a regularizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be6f859d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from utils import *\n",
    "\n",
    "# Outlined in Johnson et al.\n",
    "from transformer import TransformerNet\n",
    "\n",
    "# pretrained VGG to extract features form relu_1_2, relu_2_2, relu_3_3 and relu_4_3\n",
    "from vgg import PerceptualLossNet\n",
    "\n",
    "from torch.optim import Adam\n",
    "import time\n",
    "from PIL import Image\n",
    "import os\n",
    "import pickle\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d1718a",
   "metadata": {},
   "source": [
    "## Model Architecture\n",
    "All that's required for the perceptual loss network is a VGG16 pretrained on ImageNet. I used the Johnson et al. network for the Image Transformation Net, making a few modifications such as switching from Batch Norm to Instance Norm and other changes that are known to produce better results based on research and follow-up papers. \n",
    "\n",
    "To downsample the image, we have three convolution layers and then instance norm layers. Residual Blocks come next, and then Nearest Neighbour upsampling is used, followed by convolution layers, to achieve an output that is identical in shape to the input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abbfab24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "TRAIN_IMAGE_SIZE = 256\n",
    "DATASET_PATH = \"data\"\n",
    "NUM_EPOCHS = 1\n",
    "STYLE_IMAGE_PATH = \"style_image.jpeg\"\n",
    "CONTENT_IMAGE_PATH = \"content.jpeg\"\n",
    "BATCH_SIZE = 4\n",
    "CONTENT_WEIGHT = 1e0\n",
    "STYLE_WEIGHT = 4e5\n",
    "TV_WEIGHT = 1e-6\n",
    "LR = 0.001\n",
    "SAVE_MODEL_PATH = \"checkpoints\"\n",
    "SAVE_IMAGE_PATH = \"image_outputs\"\n",
    "CHECKPOINT_FREQ = 150\n",
    "LOG_FREQ = 50\n",
    "\n",
    "# Setting the seed value for reproducibility\n",
    "SEED = 42\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3071f9e",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "The training logic is all contained in this class. With approximately 83k images, the original MSCOCO dataset used in the literature for these models is enormous. I used a very small version of this dataset, with Training Set Size: 12417 and Validation Set Size: 165, as I did not have access to any GPUs. We use a painting by Picasso, saved as style_image.jpeg, for the style image.\n",
    "\n",
    "Because the quality of the output cannot be measured objectively and is instead dependent on personal preference and aesthetics, style transfer is by its very nature an ill-posed problem. We are limited to using the loss function as a stand-in for performance measurement as a result.\n",
    "\n",
    "The majority of the hyperparameters were taken from the paper because I lacked the tools necessary to properly tune them. We monitor the validation loss during the model selection process and select the model with the lowest validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fdc2eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StyleTransfer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_epochs=NUM_EPOCHS,\n",
    "        image_size=TRAIN_IMAGE_SIZE,\n",
    "        dataset_path=DATASET_PATH,\n",
    "        style_image_path=STYLE_IMAGE_PATH,\n",
    "        content_image_path=CONTENT_IMAGE_PATH,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        style_weight=STYLE_WEIGHT,\n",
    "        content_weight=CONTENT_WEIGHT,\n",
    "        tv_weight=TV_WEIGHT,\n",
    "        log_freq=LOG_FREQ,\n",
    "        checkpoint_freq=CHECKPOINT_FREQ,\n",
    "        lr=LR,\n",
    "        save_model_path=SAVE_MODEL_PATH,\n",
    "        save_image_path=SAVE_IMAGE_PATH\n",
    "    ):\n",
    "        self.epochs = num_epochs\n",
    "        self.image_size = image_size\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.batch_size = batch_size\n",
    "        self.dataset_path = dataset_path\n",
    "        self.style_image_path = style_image_path\n",
    "        self.content_image_path = content_image_path\n",
    "        self.content_weight = content_weight\n",
    "        self.style_weight = style_weight\n",
    "        self.tv_weight = tv_weight\n",
    "        self.lr = lr\n",
    "        self.log_freq = log_freq\n",
    "        self.checkpoint_freq = checkpoint_freq\n",
    "        self.save_model_path = save_model_path\n",
    "        self.save_image_path = save_image_path\n",
    "\n",
    "        # load data\n",
    "        print(\"Loading Data...\")\n",
    "        self.train_loader, self.val_loader = get_training_data_loader(dataset_path, image_size, batch_size)\n",
    "        print(\"Data Loaded Successfully \\n\")\n",
    "        \n",
    "        # instantiate networks\n",
    "        self.transformer_net = TransformerNet().train().to(self.device)\n",
    "        self.perceptual_loss_net = PerceptualLossNet(requires_grad=False).to(self.device)\n",
    "\n",
    "        self.optimizer = Adam(self.transformer_net.parameters())\n",
    "\n",
    "        # Compute Gram matrices for the style image\n",
    "        style_img = prepare_img(style_image_path, self.device, batch_size=batch_size)\n",
    "        style_img_set_of_feature_maps = self.perceptual_loss_net(style_img)\n",
    "        self.target_style_representation = [gram_matrix(x) for x in style_img_set_of_feature_maps]\n",
    "        \n",
    "        # This image is used to keep track of the subjective performance over the iteration\n",
    "        # sotred in the directory \"save_image_path\" after every log_iter iterations\n",
    "        self.test_image = prepare_img(content_image_path, self.device)\n",
    "        \n",
    "        self.mse_loss = torch.nn.MSELoss(reduction='mean')\n",
    "\n",
    "        self.best_val_loss = None\n",
    "        \n",
    "        self.history = {\n",
    "            'content_loss_t': [],\n",
    "            'style_loss_t': [],\n",
    "            'tv_loss_t': [],\n",
    "            'total_loss_t': [],\n",
    "            'total_loss_v' : []\n",
    "        }\n",
    "    \n",
    "    \n",
    "    def train(self):\n",
    "        print(\"Training Started...\\n\")\n",
    "        \n",
    "        ts = time.time()\n",
    "        \n",
    "        acc_content_loss, acc_style_loss, acc_tv_loss = [0., 0., 0.]\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            for batch_id, (content_batch, _) in enumerate(self.train_loader):\n",
    "                # get ouput of transform_net\n",
    "                content_batch = content_batch.to(self.device)\n",
    "                stylized_batch = self.transformer_net(content_batch)\n",
    "\n",
    "                # feed batch of style and content images to the vgg net\n",
    "                content_batch_set_of_feature_maps = self.perceptual_loss_net(content_batch)\n",
    "                stylized_batch_set_of_feature_maps = self.perceptual_loss_net(stylized_batch)\n",
    "\n",
    "                # compute content loss\n",
    "                target_content_representation = content_batch_set_of_feature_maps.relu2_2\n",
    "                current_content_representation = stylized_batch_set_of_feature_maps.relu2_2\n",
    "                content_loss = self.content_weight * self.mse_loss(target_content_representation, current_content_representation)\n",
    "                acc_content_loss += content_loss.item()\n",
    "                \n",
    "                # compute gram matrices and style loss\n",
    "                style_loss = 0.0\n",
    "                current_style_representation = [gram_matrix(x) for x in stylized_batch_set_of_feature_maps]\n",
    "                for gram_gt, gram_hat in zip(self.target_style_representation, current_style_representation):\n",
    "                    style_loss += self.mse_loss(gram_gt, gram_hat)\n",
    "                style_loss /= len(self.target_style_representation)\n",
    "                style_loss *= self.style_weight\n",
    "                acc_style_loss += style_loss.item()\n",
    "\n",
    "                # compute tv loss\n",
    "                tv_loss = self.tv_weight * total_variation(stylized_batch)\n",
    "                acc_tv_loss += tv_loss.item()\n",
    "\n",
    "                # backprop\n",
    "                total_loss = content_loss + style_loss + tv_loss\n",
    "                total_loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                \n",
    "                if (batch_id + 1) % self.log_freq == 0:\n",
    "                    with torch.no_grad():\n",
    "                        self.history['content_loss_t'].append(acc_content_loss / self.log_freq)\n",
    "                        self.history['style_loss_t'].append(acc_style_loss / self.log_freq)\n",
    "                        self.history['tv_loss_t'].append(acc_tv_loss / self.log_freq)\n",
    "                        self.history['total_loss_t'].append((acc_content_loss + acc_style_loss + acc_tv_loss) / self.log_freq)\n",
    "\n",
    "                        self.transformer_net.eval()\n",
    "                        stylized_test = self.transformer_net(self.test_image).cpu().numpy()[0]\n",
    "                        val_loss = self.val_loss()\n",
    "                        self.transformer_net.train()\n",
    "                        stylized = post_process_image(stylized_test)\n",
    "                        stylized_image = Image.fromarray(stylized)\n",
    "\n",
    "                        stylized_image.save(os.path.join(self.save_image_path, f\"iter-{batch_id + 1}.jpeg\"))\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        if self.best_val_loss is None or val_loss < self.best_val_loss:\n",
    "                            self.best_val_loss = val_loss\n",
    "                            torch.save(self.transformer_net.state_dict(), \"best_model.pth\")\n",
    "                            \n",
    "                        print(f'Iter : [{batch_id + 1}/{len(self.train_loader)}]')\n",
    "                        print('---------------------\\n')\n",
    "                        print(f'Time Elapsed : {(time.time() - ts) / 60:.2f} min)')\n",
    "                        print('Training Loss :')\n",
    "                        print(f'\\tContent Loss : {acc_content_loss / self.log_freq}')\n",
    "                        print(f'\\tStyle Loss : {acc_style_loss / self.log_freq}')\n",
    "                        print(f'\\tTV Loss : {acc_tv_loss / self.log_freq}')\n",
    "                        print(f'\\tTotal Loss : {(acc_content_loss + acc_style_loss + acc_tv_loss) / self.log_freq}')\n",
    "                        print(f'Validation Loss : {val_loss}\\n\\n')\n",
    "                    \n",
    "                        \n",
    "                        acc_content_loss, acc_style_loss, acc_tv_loss = [0., 0., 0.]\n",
    "\n",
    "                \n",
    "                if (batch_id + 1) % self.checkpoint_freq == 0:\n",
    "                    torch.save(self.transformer_net.state_dict(),\n",
    "                               os.path.join(self.save_model_path, f\"iter-{batch_id + 1}.pth\"))\n",
    "\n",
    "\n",
    "                            \n",
    "    def val_loss(self):\n",
    "        val_loss = 0.0\n",
    "        for batch_id, (content_batch, _) in enumerate(self.val_loader):\n",
    "            content_batch = content_batch.to(self.device)\n",
    "            stylized_batch = self.transformer_net(content_batch)\n",
    "            \n",
    "            content_batch_set_of_feature_maps = self.perceptual_loss_net(content_batch)\n",
    "            stylized_batch_set_of_feature_maps = self.perceptual_loss_net(stylized_batch)\n",
    "            \n",
    "            target_content_representation = content_batch_set_of_feature_maps.relu2_2\n",
    "            current_content_representation = stylized_batch_set_of_feature_maps.relu2_2\n",
    "            content_loss = self.content_weight * self.mse_loss(target_content_representation, current_content_representation)\n",
    "\n",
    "            style_loss = 0.0\n",
    "            current_style_representation = [gram_matrix(x) for x in stylized_batch_set_of_feature_maps]\n",
    "            for gram_gt, gram_hat in zip(self.target_style_representation, current_style_representation):\n",
    "                style_loss += self.mse_loss(gram_gt, gram_hat)\n",
    "            style_loss /= len(self.target_style_representation)\n",
    "            style_loss *= self.style_weight\n",
    "            \n",
    "            tv_loss = self.tv_weight * total_variation(stylized_batch)\n",
    "\n",
    "            val_loss += (content_loss + style_loss + tv_loss).item()\n",
    "            \n",
    "        val_loss /= len(self.val_loader)\n",
    "        self.history['total_loss_v'].append(val_loss)\n",
    "                \n",
    "        return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5cd6afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data...\n",
      "Training Set Size : 12417\n",
      "Validation Set Size : 165\n",
      "Data Loaded Successfully \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to C:\\Users\\aravi/.cache\\torch\\hub\\checkpoints\\vgg16-397923af.pth\n"
     ]
    }
   ],
   "source": [
    "style_transfer = StyleTransfer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2db2432d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Started...\n",
      "\n",
      "Iter : [50/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 5.77 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 5.934230990409851\n",
      "\tStyle Loss : 22.252575950622557\n",
      "\tTV Loss : 0.010350680965930224\n",
      "\tTotal Loss : 28.19715762199834\n",
      "Validation Loss : 15.733688912740568\n",
      "\n",
      "\n",
      "Iter : [100/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 11.45 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 6.26154577255249\n",
      "\tStyle Loss : 7.451888561248779\n",
      "\tTV Loss : 0.016604524552822113\n",
      "\tTotal Loss : 13.730038858354092\n",
      "Validation Loss : 12.597650248829911\n",
      "\n",
      "\n",
      "Iter : [150/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 17.46 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 6.3648433589935305\n",
      "\tStyle Loss : 4.920478434562683\n",
      "\tTV Loss : 0.02767215568572283\n",
      "\tTotal Loss : 11.312993949241935\n",
      "Validation Loss : 10.680499867695135\n",
      "\n",
      "\n",
      "Iter : [200/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 24.43 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 6.170740432739258\n",
      "\tStyle Loss : 3.595876622200012\n",
      "\tTV Loss : 0.035476987957954405\n",
      "\tTotal Loss : 9.802094042897224\n",
      "Validation Loss : 9.303438151754984\n",
      "\n",
      "\n",
      "Iter : [250/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 31.43 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 6.133468933105469\n",
      "\tStyle Loss : 2.5805429434776306\n",
      "\tTV Loss : 0.04393867336213589\n",
      "\tTotal Loss : 8.757950549945235\n",
      "Validation Loss : 8.215441668905862\n",
      "\n",
      "\n",
      "Iter : [300/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 38.96 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 5.539395847320557\n",
      "\tStyle Loss : 2.1658810925483705\n",
      "\tTV Loss : 0.04856135196983814\n",
      "\tTotal Loss : 7.753838291838765\n",
      "Validation Loss : 7.673507434565846\n",
      "\n",
      "\n",
      "Iter : [350/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 46.24 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 5.307248072624207\n",
      "\tStyle Loss : 1.9102297806739807\n",
      "\tTV Loss : 0.05118067592382431\n",
      "\tTotal Loss : 7.268658529222011\n",
      "Validation Loss : 7.211152658229921\n",
      "\n",
      "\n",
      "Iter : [400/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 51.84 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 4.910494179725647\n",
      "\tStyle Loss : 1.7629100823402404\n",
      "\tTV Loss : 0.05289141103625297\n",
      "\tTotal Loss : 6.726295673102141\n",
      "Validation Loss : 6.869922440226485\n",
      "\n",
      "\n",
      "Iter : [450/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 57.25 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 4.870007290840149\n",
      "\tStyle Loss : 1.6722704005241393\n",
      "\tTV Loss : 0.05457614965736866\n",
      "\tTotal Loss : 6.596853841021657\n",
      "Validation Loss : 6.610636780901653\n",
      "\n",
      "\n",
      "Iter : [500/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 62.64 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 4.66583484172821\n",
      "\tStyle Loss : 1.5962809228897095\n",
      "\tTV Loss : 0.0547063921391964\n",
      "\tTotal Loss : 6.316822156757116\n",
      "Validation Loss : 6.43402895113317\n",
      "\n",
      "\n",
      "Iter : [550/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 67.82 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 4.545675730705261\n",
      "\tStyle Loss : 1.555772385597229\n",
      "\tTV Loss : 0.05517647638916969\n",
      "\tTotal Loss : 6.15662459269166\n",
      "Validation Loss : 6.344008585301841\n",
      "\n",
      "\n",
      "Iter : [600/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 73.10 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 4.386261324882508\n",
      "\tStyle Loss : 1.4381597471237182\n",
      "\tTV Loss : 0.05564465031027794\n",
      "\tTotal Loss : 5.880065722316504\n",
      "Validation Loss : 6.095644346097621\n",
      "\n",
      "\n",
      "Iter : [650/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 89.67 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 4.393239250183106\n",
      "\tStyle Loss : 1.5030400657653809\n",
      "\tTV Loss : 0.05577255927026272\n",
      "\tTotal Loss : 5.952051875218749\n",
      "Validation Loss : 6.05371164694065\n",
      "\n",
      "\n",
      "Iter : [700/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 95.34 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 4.384355697631836\n",
      "\tStyle Loss : 1.4454710793495178\n",
      "\tTV Loss : 0.0561136582493782\n",
      "\tTotal Loss : 5.885940435230732\n",
      "Validation Loss : 5.991509612013654\n",
      "\n",
      "\n",
      "Iter : [750/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 101.38 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 4.296465482711792\n",
      "\tStyle Loss : 1.5651238584518432\n",
      "\tTV Loss : 0.05569710291922093\n",
      "\tTotal Loss : 5.9172864440828565\n",
      "Validation Loss : 5.879398799524075\n",
      "\n",
      "\n",
      "Iter : [800/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 107.45 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 4.232857213020325\n",
      "\tStyle Loss : 1.4170344924926759\n",
      "\tTV Loss : 0.056039946973323825\n",
      "\tTotal Loss : 5.705931652486324\n",
      "Validation Loss : 5.697746904884896\n",
      "\n",
      "\n",
      "Iter : [850/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 114.43 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 4.1170835781097415\n",
      "\tStyle Loss : 1.4288559818267823\n",
      "\tTV Loss : 0.056093478575348854\n",
      "\tTotal Loss : 5.602033038511872\n",
      "Validation Loss : 5.697879070188941\n",
      "\n",
      "\n",
      "Iter : [900/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 120.48 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 4.194075961112976\n",
      "\tStyle Loss : 1.4364990842342378\n",
      "\tTV Loss : 0.05609485365450382\n",
      "\tTotal Loss : 5.686669899001718\n",
      "Validation Loss : 5.676391706234071\n",
      "\n",
      "\n",
      "Iter : [950/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 126.86 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 4.0634270286560055\n",
      "\tStyle Loss : 1.355635187625885\n",
      "\tTV Loss : 0.05631033644080162\n",
      "\tTotal Loss : 5.475372552722693\n",
      "Validation Loss : 5.5317460502066265\n",
      "\n",
      "\n",
      "Iter : [1000/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 132.68 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 3.964728903770447\n",
      "\tStyle Loss : 1.36216859459877\n",
      "\tTV Loss : 0.056138371974229814\n",
      "\tTotal Loss : 5.383035870343447\n",
      "Validation Loss : 5.4467892065280825\n",
      "\n",
      "\n",
      "Iter : [1050/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 138.36 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 3.7952556371688844\n",
      "\tStyle Loss : 1.2971249985694886\n",
      "\tTV Loss : 0.05600589312613011\n",
      "\tTotal Loss : 5.148386528864503\n",
      "Validation Loss : 5.409299990025962\n",
      "\n",
      "\n",
      "Iter : [1100/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 144.02 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 3.9609596300125123\n",
      "\tStyle Loss : 1.351389148235321\n",
      "\tTV Loss : 0.05608566276729107\n",
      "\tTotal Loss : 5.368434441015125\n",
      "Validation Loss : 5.353924844323135\n",
      "\n",
      "\n",
      "Iter : [1150/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 149.74 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 3.832208595275879\n",
      "\tStyle Loss : 1.2849183356761933\n",
      "\tTV Loss : 0.05636532984673977\n",
      "\tTotal Loss : 5.173492260798812\n",
      "Validation Loss : 5.307173066022919\n",
      "\n",
      "\n",
      "Iter : [1200/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 155.49 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 3.8211576080322267\n",
      "\tStyle Loss : 1.3095728802680968\n",
      "\tTV Loss : 0.05611419446766377\n",
      "\tTotal Loss : 5.186844682767987\n",
      "Validation Loss : 5.272233323353093\n",
      "\n",
      "\n",
      "Iter : [1250/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 161.34 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 3.8040949535369872\n",
      "\tStyle Loss : 1.3273735785484313\n",
      "\tTV Loss : 0.05571499779820442\n",
      "\tTotal Loss : 5.187183529883623\n",
      "Validation Loss : 5.252610892784305\n",
      "\n",
      "\n",
      "Iter : [1300/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 167.45 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 3.755842938423157\n",
      "\tStyle Loss : 1.279553828239441\n",
      "\tTV Loss : 0.05633182898163795\n",
      "\tTotal Loss : 5.091728595644236\n",
      "Validation Loss : 5.238817028883027\n",
      "\n",
      "\n",
      "Iter : [1350/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 173.23 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 3.521509876251221\n",
      "\tStyle Loss : 1.2877114021778107\n",
      "\tTV Loss : 0.05585360437631607\n",
      "\tTotal Loss : 4.865074882805348\n",
      "Validation Loss : 5.293039973189191\n",
      "\n",
      "\n",
      "Iter : [1400/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 178.96 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 3.6964257907867433\n",
      "\tStyle Loss : 1.2801047599315643\n",
      "\tTV Loss : 0.05598920181393623\n",
      "\tTotal Loss : 5.032519752532243\n",
      "Validation Loss : 5.120617348973344\n",
      "\n",
      "\n",
      "Iter : [1450/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 184.93 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 3.709074869155884\n",
      "\tStyle Loss : 1.2364533698558808\n",
      "\tTV Loss : 0.05618555493652821\n",
      "\tTotal Loss : 5.0017137939482925\n",
      "Validation Loss : 5.0321442208639\n",
      "\n",
      "\n",
      "Iter : [1500/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 190.85 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 3.5748739719390867\n",
      "\tStyle Loss : 1.2126406860351562\n",
      "\tTV Loss : 0.055905189141631124\n",
      "\tTotal Loss : 4.843419847115874\n",
      "Validation Loss : 5.0760781183475405\n",
      "\n",
      "\n",
      "Iter : [1550/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 196.62 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 3.476997175216675\n",
      "\tStyle Loss : 1.2502450847625732\n",
      "\tTV Loss : 0.05585183344781399\n",
      "\tTotal Loss : 4.783094093427062\n",
      "Validation Loss : 5.0220413440611305\n",
      "\n",
      "\n",
      "Iter : [1600/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 202.42 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 3.663522253036499\n",
      "\tStyle Loss : 1.308771002292633\n",
      "\tTV Loss : 0.05583386309444904\n",
      "\tTotal Loss : 5.028127118423581\n",
      "Validation Loss : 5.049453438782111\n",
      "\n",
      "\n",
      "Iter : [1650/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 209.02 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 3.52706316947937\n",
      "\tStyle Loss : 1.2592598521709442\n",
      "\tTV Loss : 0.05601721897721291\n",
      "\tTotal Loss : 4.842340240627527\n",
      "Validation Loss : 4.944391965866089\n",
      "\n",
      "\n",
      "Iter : [1700/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 216.01 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 3.4059873390197755\n",
      "\tStyle Loss : 1.2197374820709228\n",
      "\tTV Loss : 0.05596715971827507\n",
      "\tTotal Loss : 4.681691980808973\n",
      "Validation Loss : 4.920602943839096\n",
      "\n",
      "\n",
      "Iter : [1750/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 223.23 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 3.385645880699158\n",
      "\tStyle Loss : 1.1876779723167419\n",
      "\tTV Loss : 0.05621011011302471\n",
      "\tTotal Loss : 4.6295339631289245\n",
      "Validation Loss : 4.896533367110462\n",
      "\n",
      "\n",
      "Iter : [1800/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 229.50 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 3.3819702434539796\n",
      "\tStyle Loss : 1.178176633119583\n",
      "\tTV Loss : 0.0562072192877531\n",
      "\tTotal Loss : 4.616354095861316\n",
      "Validation Loss : 4.805745560948441\n",
      "\n",
      "\n",
      "Iter : [1850/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 235.45 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 3.4531745672225953\n",
      "\tStyle Loss : 1.2162566900253295\n",
      "\tTV Loss : 0.05607101738452911\n",
      "\tTotal Loss : 4.725502274632454\n",
      "Validation Loss : 4.831506188322858\n",
      "\n",
      "\n",
      "Iter : [1900/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 241.22 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 3.4974447202682497\n",
      "\tStyle Loss : 1.2241832613945007\n",
      "\tTV Loss : 0.05596647530794144\n",
      "\tTotal Loss : 4.777594456970692\n",
      "Validation Loss : 4.814970975968896\n",
      "\n",
      "\n",
      "Iter : [1950/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 247.14 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 3.4785901737213134\n",
      "\tStyle Loss : 1.2090316653251647\n",
      "\tTV Loss : 0.05594614632427693\n",
      "\tTotal Loss : 4.743567985370755\n",
      "Validation Loss : 4.745008631450374\n",
      "\n",
      "\n",
      "Iter : [2000/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 253.13 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 3.4156225967407225\n",
      "\tStyle Loss : 1.2000311756134032\n",
      "\tTV Loss : 0.05596386209130287\n",
      "\tTotal Loss : 4.671617634445429\n",
      "Validation Loss : 4.72811860573001\n",
      "\n",
      "\n",
      "Iter : [2050/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 259.00 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 3.4657505798339843\n",
      "\tStyle Loss : 1.263348491191864\n",
      "\tTV Loss : 0.05566066674888134\n",
      "\tTotal Loss : 4.7847597377747295\n",
      "Validation Loss : 4.729964831980263\n",
      "\n",
      "\n",
      "Iter : [2100/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 264.94 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 3.3853405475616456\n",
      "\tStyle Loss : 1.2160892701148986\n",
      "\tTV Loss : 0.05600264713168144\n",
      "\tTotal Loss : 4.657432464808226\n",
      "Validation Loss : 4.651684801752975\n",
      "\n",
      "\n",
      "Iter : [2150/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 270.97 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 3.207114996910095\n",
      "\tStyle Loss : 1.1553160846233368\n",
      "\tTV Loss : 0.055901818796992304\n",
      "\tTotal Loss : 4.418332900330424\n",
      "Validation Loss : 4.6229936146154635\n",
      "\n",
      "\n",
      "Iter : [2200/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 276.96 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 3.373787450790405\n",
      "\tStyle Loss : 1.195708544254303\n",
      "\tTV Loss : 0.055969503298401835\n",
      "\tTotal Loss : 4.62546549834311\n",
      "Validation Loss : 4.586455717319396\n",
      "\n",
      "\n",
      "Iter : [2250/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 282.79 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 3.3082450675964354\n",
      "\tStyle Loss : 1.1944947779178618\n",
      "\tTV Loss : 0.05568784601986408\n",
      "\tTotal Loss : 4.5584276915341615\n",
      "Validation Loss : 4.637316628200252\n",
      "\n",
      "\n",
      "Iter : [2300/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 289.12 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 3.2718727207183838\n",
      "\tStyle Loss : 1.1817846989631653\n",
      "\tTV Loss : 0.055902433544397355\n",
      "\tTotal Loss : 4.509559853225946\n",
      "Validation Loss : 4.582133921181283\n",
      "\n",
      "\n",
      "Iter : [2350/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 295.51 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 3.2010773849487304\n",
      "\tStyle Loss : 1.1746170496940613\n",
      "\tTV Loss : 0.055998183712363245\n",
      "\tTotal Loss : 4.431692618355155\n",
      "Validation Loss : 4.575322063957772\n",
      "\n",
      "\n",
      "Iter : [2400/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 301.95 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 3.006525182723999\n",
      "\tStyle Loss : 1.1463392770290375\n",
      "\tTV Loss : 0.05574350833892822\n",
      "\tTotal Loss : 4.208607968091965\n",
      "Validation Loss : 4.5536070684107335\n",
      "\n",
      "\n",
      "Iter : [2450/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 308.21 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 3.356375298500061\n",
      "\tStyle Loss : 1.2169580161571503\n",
      "\tTV Loss : 0.05586578406393528\n",
      "\tTotal Loss : 4.629199098721147\n",
      "Validation Loss : 4.681105730010242\n",
      "\n",
      "\n",
      "Iter : [2500/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 316.08 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 3.1387870597839354\n",
      "\tStyle Loss : 1.174907901287079\n",
      "\tTV Loss : 0.05590427681803703\n",
      "\tTotal Loss : 4.369599237889052\n",
      "Validation Loss : 4.510530524137543\n",
      "\n",
      "\n",
      "Iter : [2550/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 324.45 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 3.166224937438965\n",
      "\tStyle Loss : 1.1948643839359283\n",
      "\tTV Loss : 0.0557928716391325\n",
      "\tTotal Loss : 4.416882193014025\n",
      "Validation Loss : 4.4904899190111855\n",
      "\n",
      "\n",
      "Iter : [2600/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 331.94 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 3.1002559518814086\n",
      "\tStyle Loss : 1.1285819935798644\n",
      "\tTV Loss : 0.05583893194794655\n",
      "\tTotal Loss : 4.28467687740922\n",
      "Validation Loss : 4.501904656247395\n",
      "\n",
      "\n",
      "Iter : [2650/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 339.10 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 3.1673557949066162\n",
      "\tStyle Loss : 1.1760357856750487\n",
      "\tTV Loss : 0.05590733617544174\n",
      "\tTotal Loss : 4.399298916757107\n",
      "Validation Loss : 4.409833803409484\n",
      "\n",
      "\n",
      "Iter : [2700/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 345.99 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 3.1682045364379885\n",
      "\tStyle Loss : 1.1721851646900177\n",
      "\tTV Loss : 0.05583047047257424\n",
      "\tTotal Loss : 4.39622017160058\n",
      "Validation Loss : 4.403925395593411\n",
      "\n",
      "\n",
      "Iter : [2750/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 353.33 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 2.9282990026474\n",
      "\tStyle Loss : 1.1725145411491393\n",
      "\tTV Loss : 0.05522862069308758\n",
      "\tTotal Loss : 4.156042164489627\n",
      "Validation Loss : 4.408470839988895\n",
      "\n",
      "\n",
      "Iter : [2800/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 358.51 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 3.018883676528931\n",
      "\tStyle Loss : 1.1433668088912965\n",
      "\tTV Loss : 0.055941765755414964\n",
      "\tTotal Loss : 4.218192251175642\n",
      "Validation Loss : 4.371169392655536\n",
      "\n",
      "\n",
      "Iter : [2850/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 363.48 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 2.9452519369125367\n",
      "\tStyle Loss : 1.1588731276988984\n",
      "\tTV Loss : 0.055439715087413785\n",
      "\tTotal Loss : 4.159564779698849\n",
      "Validation Loss : 4.356701286827645\n",
      "\n",
      "\n",
      "Iter : [2900/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 368.36 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 3.061375322341919\n",
      "\tStyle Loss : 1.189185655117035\n",
      "\tTV Loss : 0.05558665379881859\n",
      "\tTotal Loss : 4.3061476312577724\n",
      "Validation Loss : 4.383583946925838\n",
      "\n",
      "\n",
      "Iter : [2950/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 373.08 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 2.953888339996338\n",
      "\tStyle Loss : 1.168813589811325\n",
      "\tTV Loss : 0.05548517942428589\n",
      "\tTotal Loss : 4.178187109231949\n",
      "Validation Loss : 4.310585138274402\n",
      "\n",
      "\n",
      "Iter : [3000/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 377.79 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 3.0636529541015625\n",
      "\tStyle Loss : 1.1473815989494325\n",
      "\tTV Loss : 0.055534132421016694\n",
      "\tTotal Loss : 4.266568685472012\n",
      "Validation Loss : 4.2935438737636655\n",
      "\n",
      "\n",
      "Iter : [3050/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 382.47 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 2.9488555431365966\n",
      "\tStyle Loss : 1.145882444381714\n",
      "\tTV Loss : 0.05540085092186928\n",
      "\tTotal Loss : 4.15013883844018\n",
      "Validation Loss : 4.3897090830454015\n",
      "\n",
      "\n",
      "Iter : [3100/3104]\n",
      "---------------------\n",
      "\n",
      "Time Elapsed : 387.17 min)\n",
      "Training Loss :\n",
      "\tContent Loss : 2.9474469232559204\n",
      "\tStyle Loss : 1.131705071926117\n",
      "\tTV Loss : 0.05550276979804039\n",
      "\tTotal Loss : 4.134654764980078\n",
      "Validation Loss : 4.278036111738624\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "style_transfer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4925c58e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1af61332ac0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "log_dict = style_transfer.history\n",
    "\n",
    "x = np.linspace(1, len(log_dict['content_loss_t'])*style_transfer.log_freq, len(log_dict['content_loss_t']))\n",
    "plt.plot(x, log_dict['content_loss_t'], label='Content Loss')\n",
    "plt.plot(x, log_dict['style_loss_t'], label='Style Loss')\n",
    "plt.plot(x, log_dict['tv_loss_t'], label='TV Loss')\n",
    "plt.plot(x, log_dict['total_loss_t'], label='Training Loss Total')\n",
    "\n",
    "plt.xlabel('Iteration')\n",
    "plt.title('Traingin Log History')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c664855",
   "metadata": {},
   "source": [
    "## Improvements and Further Scope\n",
    "\n",
    "- There were significantly fewer feasible methods in the literature to explore due to severe time and resource constraints. Therefore, better results would have come from a more extensive literature review.\n",
    "\n",
    "- This method itself could be made even more effective with proper hyperparameter tweaking. There may have been less loss if an LR scheduler had been used as well.\n",
    "\n",
    "- Overall, with more time and adequate processing power, a lot more experimentation could have been conducted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ea0bde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
